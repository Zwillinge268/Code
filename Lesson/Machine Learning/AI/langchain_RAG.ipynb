{"cells":[{"cell_type":"markdown","metadata":{"id":"ANkd7u1TK92b"},"source":["# 安裝需要的套件\n","* langchain：基本的langchain套件\n","* openai：基本的openai套件\n","* unstructured：讀取文字檔格式的套件\n","* chromadb：向量儲存資料庫\n","* tiktoken套件：OpenAI算token數的套件"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e9dWmxdK92c"},"outputs":[],"source":["!pip install langchain\n","# !pip install openai\n","!pip install langchain-openai\n","!pip install unstructured\n","!pip install chromadb\n","!pip install tiktoken\n","!pip install tabulate"]},{"cell_type":"markdown","metadata":{"id":"DdedMiSsK92d"},"source":["## 將環境變數讀入"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxT0u_yYK92d"},"outputs":[],"source":["# 導入 ColabSecrets 用戶資料模組\n","from google.colab import userdata\n","\n","# 設置 OpenAI API key\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"markdown","metadata":{"id":"pU3QjAFZK92d"},"source":["### 先套用OpenAI的API\n","使用`langchain`中的`OpenAI`套件載入大型語言模型，載入OpenAi模型，並且設定最大輸出長度為1024。此部分會收費"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_LvzHrnK92e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327836353,"user_tz":-480,"elapsed":1894,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"3df158e0-3142-490f-865f-9e34644ea0dd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n"]}],"source":["from langchain.chat_models import ChatOpenAI\n","llm = ChatOpenAI(\n","    model_name=\"gpt-3.5-turbo\",\n","    temperature=0.3,\n","    max_tokens=512,\n","    )"]},{"cell_type":"markdown","source":["### 測試沒有RAG時候的問答"],"metadata":{"id":"Kryz-tpi3ZTE"}},{"cell_type":"code","source":["llm.invoke(\"工專時期第3任校長是誰?\")"],"metadata":{"id":"k6nBEb9qsgdc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327838879,"user_tz":-480,"elapsed":1263,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"71b80fb6-7a53-42c5-d863-9071bc4a823a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='工專時期第3任校長是王瑞榮。', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 23, 'total_tokens': 45}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4e723af0-6d59-4a45-846f-a44019a37323-0')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["llm.invoke(\"明新科技大學的校訓是什麼?\")"],"metadata":{"id":"FEfGohnT3YAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327841233,"user_tz":-480,"elapsed":1103,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"f8a72f59-3003-4be7-cbdc-65a0f3bd9aae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='明新科技大學的校訓是「誠樸勵志、求實創新」。', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 26, 'total_tokens': 57}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-95d62033-e8ac-48c1-a95c-eb6626fcc73c-0')"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"f_NDQiasK92f"},"source":["### 建立本機知識庫QA機器人\n","[Document loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2KsjlHTK92f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327906195,"user_tz":-480,"elapsed":13955,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"fd182ab5-db90-4deb-9b72-d316ed59c57f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:unstructured:The MIME type of '/content/must.txt' is 'application/x-wine-extension-ini'. This file type is not currently supported in unstructured.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","WARNING:langchain_text_splitters.base:Created a chunk of size 153, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 109, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 126, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 124, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 167, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 135, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 118, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 110, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 104, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 149, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 297, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 289, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 188, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 143, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 315, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 175, which is longer than the specified 100\n","/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py:289: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["工專時期第三任校長是林世明。\n"]}],"source":["from langchain_openai import OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain import OpenAI,VectorDBQA\n","from langchain.document_loaders import DirectoryLoader\n","\n","# 載入資料夾中所有TXT檔案\n","loader = DirectoryLoader('/content/', glob='**/*.txt')\n","\n","# 將資料轉成document物佚，每個檔案會為作為一個document\n","documents = loader.load()\n","\n","# 初始化載入器\n","text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n","\n","# 切割加载的 document\n","split_docs = text_splitter.split_documents(documents)\n","\n","# 初始化 openai 的 embeddings 物件\n","embeddings = OpenAIEmbeddings()\n","\n","# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n","docsearch = Chroma.from_documents(split_docs, embeddings)\n","\n","# 建立回答物件\n","qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n","\n","# 進行回答\n","result = qa({\"query\": \"工專時期第3任校長是誰?\"})\n","print(result['result'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH35TKRmK92g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327914189,"user_tz":-480,"elapsed":1483,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"9ba25e54-e26a-4fb7-86ec-b1e999c75277"},"outputs":[{"output_type":"stream","name":"stdout","text":["現行明新科技大學之校訓為「堅毅、求新、創造」。\n"]}],"source":["result = qa({\"query\": \"現行明新科技大學之校訓?\"})\n","print(result['result'])"]},{"cell_type":"markdown","source":["文件分割器的chunk_overlap參數，切分後每個文件裡包含幾個上一個文件結尾的內容，主要作用是為了增加每個文件的上下文關聯。比如chunk_overlap=0時，第一個文件為aaaaaa，第二個為bbbbbb；當chunk_overlap=2時，第一個文件為aaaaaa，第二個為aabbbbbb。"],"metadata":{"id":"CMESifqj22KL"}},{"cell_type":"markdown","metadata":{"id":"hiiu3ZiqK92g"},"source":["## 替模型加入記憶功能\n","「對話記憶體」（ConversationBufferMemory）用於儲存簡單的對話歷史 \\\n","[ConversationBufferMemory](https://python.langchain.com/docs/modules/memory/types/buffer/) \\\n","[memory_management](https://python.langchain.com/docs/use_cases/chatbots/memory_management/)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbWrd1YoK92g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327917244,"user_tz":-480,"elapsed":287,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"d1a9ed46-ad64-47c0-f7f7-b757a350ee08"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n","  warn_deprecated(\n"]}],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import (\n","    ChatPromptTemplate,\n","    MessagesPlaceholder,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.chains import LLMChain\n","from langchain.memory import ConversationBufferMemory\n","\n","# 建立記憶體實例，開啟 return_messages 是為了將記憶體指定給 chat模型\n","# 而 memory_key則是可以讓我們客制我們取得對話記錄時用的 key 值\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","\n","# 建立 chat 語言模型\n","# llm_chat = ChatOpenAI()\n","\n","# 提示設計\n","prompt_chat = ChatPromptTemplate(\n","    messages=[\n","        SystemMessagePromptTemplate.from_template(\n","            \"你是一個友善的學習助理，你接下來會跟使用者來對話。\"\n","        ),\n","        # 這裏是一個讓記憶體資料填空的地方。\n","        # 我們也要設定，使用chat_history 來取得對話記錄\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        HumanMessagePromptTemplate.from_template(\"{question}\")\n","    ]\n",")\n","\n","conversation_chat = LLMChain(\n","    llm=llm,\n","    prompt=prompt_chat,\n","    verbose=True,\n","    memory=memory\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cbzh-3woK92g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327922596,"user_tz":-480,"elapsed":1145,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"0eb8a758-0da5-46f5-cef2-ac9602eba107"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: 你是一個友善的學習助理，你接下來會跟使用者來對話。\n","Human: 你好\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'question': '你好',\n"," 'chat_history': [HumanMessage(content='你好'),\n","  AIMessage(content='你好！有什麼問題我可以幫助你解答嗎？')],\n"," 'text': '你好！有什麼問題我可以幫助你解答嗎？'}"]},"metadata":{},"execution_count":9}],"source":["conversation_chat({\n","    'question': '你好'\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srMS_TyXK92g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327927386,"user_tz":-480,"elapsed":2442,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"8bc671a7-7f76-4c80-a489-f54cb565bb29"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new LLMChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: 你是一個友善的學習助理，你接下來會跟使用者來對話。\n","Human: 你好\n","AI: 你好！有什麼問題我可以幫助你解答嗎？\n","Human: 你可以告訴我英國和美國的首都在哪裡嗎?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'question': '你可以告訴我英國和美國的首都在哪裡嗎?',\n"," 'chat_history': [HumanMessage(content='你好'),\n","  AIMessage(content='你好！有什麼問題我可以幫助你解答嗎？'),\n","  HumanMessage(content='你可以告訴我英國和美國的首都在哪裡嗎?'),\n","  AIMessage(content='當然可以！英國的首都是倫敦（London），而美國的首都是華盛頓特區（Washington, D.C.）。希望這個資訊對你有幫助！如果有任何其他問題，歡迎隨時問我。')],\n"," 'text': '當然可以！英國的首都是倫敦（London），而美國的首都是華盛頓特區（Washington, D.C.）。希望這個資訊對你有幫助！如果有任何其他問題，歡迎隨時問我。'}"]},"metadata":{},"execution_count":10}],"source":["conversation_chat({\n","    'question': '你可以告訴我英國和美國的首都在哪裡嗎?'\n","})"]},{"cell_type":"code","source":["#查詢記憶內容\n","print(\"chat_history:\", memory.load_memory_variables({}))"],"metadata":{"id":"a8Y1dcHLxvFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327929855,"user_tz":-480,"elapsed":308,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"088d0aee-400c-47cd-a823-83751b01e026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["chat_history: {'chat_history': [HumanMessage(content='你好'), AIMessage(content='你好！有什麼問題我可以幫助你解答嗎？'), HumanMessage(content='你可以告訴我英國和美國的首都在哪裡嗎?'), AIMessage(content='當然可以！英國的首都是倫敦（London），而美國的首都是華盛頓特區（Washington, D.C.）。希望這個資訊對你有幫助！如果有任何其他問題，歡迎隨時問我。')]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"GZE-HyHAK92h"},"source":["## 進階記憶功能"]},{"cell_type":"markdown","metadata":{"id":"jUyJONY6K92h"},"source":["##### ConversationBufferWindowMemory 類別\n","直譯為「局部窗口對話記憶體」。它的主要功能是限制在一個局部窗口內保存的對話資訊。由於 token 的運算資源有限且需消耗費用，甚至如果語言模型是我們自己架設的，同樣需要大量的運算資源，因此我們不能讓歷史對話資料無窮無盡地累積。\n","\n","使用ConversationBufferWindowMemory 類別，可以只保存最近的 k 條訊息。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hG2rlNm5K92h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327933609,"user_tz":-480,"elapsed":489,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"c49ec8f9-b5b0-4814-c7a6-2d3b1cfd48b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: 這是最新的訊息\\nAI: 只會記錄這個訊息！'}"]},"metadata":{},"execution_count":12}],"source":["from langchain.memory import ConversationBufferWindowMemory\n","\n","# 建立 ConversationBufferWindowMemory 實例, k=1 即限制一條訊息\n","memory_buffer_window = ConversationBufferWindowMemory(k=1)\n","\n","# 更新上下文資訊\n","memory_buffer_window.save_context({\"input\": \"你好！\"}, {\"output\": \"什麼事？\"})\n","memory_buffer_window.save_context({\"input\": \"今天天氣真好！\"}, {\"output\": \"我覺得太熱了！\"})\n","memory_buffer_window.save_context({\"input\": \"這是最新的訊息\"}, {\"output\": \"只會記錄這個訊息！\"})\n","# 取得記憶體內儲存的資訊\n","memory_buffer_window.load_memory_variables({})\n","\n","#--- 實際的輸出 ---\n","\n","# {'history': 'Human: 這是最新的訊息\\nAI: 只會記錄這個訊息！'}"]},{"cell_type":"markdown","metadata":{"id":"3XQqzWo6K92h"},"source":["##### 使用 Vector Store 做為儲存後端的記憶單元\n","可以參考 VectorStoreRetrieverMemory 這樣的方法，設計我們的 LLMChain 來擷取背景資料。\n","\n","值得特別提及的是，VectorStoreRetrieverMemory 不只能夠從向量資料庫中檢索相似度資料，它還會在對話過程中將我們的對話記錄保存到向量資料中。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAtiXWM1K92h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327938962,"user_tz":-480,"elapsed":1372,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"52ef8f46-06b1-42fa-9c57-c84a8cf81cd2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["{'history': 'Human: 我最喜歡的運動是游泳\\nAI: 很高興你跟我說分享你的嗜好。'}\n"]}],"source":["# 下方是建立向量資料庫的部分\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.memory import VectorStoreRetrieverMemory\n","\n","db_chroma = Chroma(embedding_function=OpenAIEmbeddings())\n","\n","retriever = db_chroma.as_retriever(search_kwargs=dict(k=1))\n","\n","memory_vs = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n","\n","# 這裏是模擬我們已經有三個對話記錄\n","memory_vs.save_context({\"Human\": \"我最喜歡的食物是披薩\"}, {\"AI\": \"這樣很棒！\"})\n","memory_vs.save_context({\"Human\": \"我最喜歡的運動是游泳\"}, {\"AI\": \"很高興你跟我說分享你的嗜好。\"})\n","memory_vs.save_context({\"Human\": \"我不喜歡上班\"}, {\"AI\": \"瞭解\"})\n","memory_vs.save_context({\"Human\": \"奇奇自助餐很貴\"}, {\"AI\": \"太糟糕了\"})\n","\n","# 使用 load_memory_varialbes 取得使用者問題相似度的歷史資料\n","print(memory_vs.load_memory_variables({\"prompt\": \"我該看什麼運動節目？\"}))\n","# print(memory_vs.load_memory_variables({\"prompt\": \"昂貴的店家\"}))"]},{"cell_type":"markdown","metadata":{"id":"61VfZwzvK92h"},"source":["## 整合"]},{"cell_type":"markdown","source":["[Chain類別](https://python.langchain.com/docs/modules/chains/)"],"metadata":{"id":"eg7CuDXPKx9b"}},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.document_loaders import DirectoryLoader\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import ConversationChain\n","from langchain.memory import VectorStoreRetrieverMemory\n","\n","# 載入資料夾中所有TXT檔案\n","loader = DirectoryLoader('/content/', glob='**/*.txt')\n","\n","# 將資料轉成document物佚，每個檔案會為作為一個document\n","documents = loader.load()\n","\n","# 初始化載入器\n","text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n","\n","# 切割加载的 document\n","split_docs = text_splitter.split_documents(documents)\n","\n","# 初始化 openai 的 embeddings 物件\n","embeddings = OpenAIEmbeddings()\n","\n","# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n","\n","docsearch = Chroma.from_documents(split_docs, embeddings)\n","\n","# 建立檢索器\n","retriever = docsearch.as_retriever()\n","\n","# 建立記憶體\n","memory_vs = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n","\n","# 設置預設的prompt\n","DEFAULT_TEMPLATE = \"\"\"\n","你是一個友善的對話機器人，下面歷史記錄是我們曾經的對話。\n","Human 是我，AI 是你。請根據歷史記錄中的資訊來回覆我的新問題。\n","\n","歷史記錄:\n","{history}\n","\n","Human：{input}\n","AI：\n","\"\"\"\n","PROMPT = PromptTemplate(\n","    input_variables=[\"history\", \"input\"], template=DEFAULT_TEMPLATE\n",")\n","conversation_with_memory_vs = ConversationChain(\n","    llm=llm,\n","    prompt=PROMPT,\n","    memory=memory_vs,\n","    # verbose=True,\n","    output_key='AI'\n",")"],"metadata":{"id":"e2I11VaMwyOq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715327945713,"user_tz":-480,"elapsed":3411,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"a23e345b-6b3e-4b00-9337-b4c254ea0c34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:unstructured:The MIME type of '/content/must.txt' is 'application/x-wine-extension-ini'. This file type is not currently supported in unstructured.\n","WARNING:langchain_text_splitters.base:Created a chunk of size 153, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 109, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 126, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 124, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 167, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 135, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 118, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 110, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 104, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 149, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 297, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 289, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 188, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 143, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 315, which is longer than the specified 100\n","WARNING:langchain_text_splitters.base:Created a chunk of size 175, which is longer than the specified 100\n"]}]},{"cell_type":"code","source":["conversation_with_memory_vs.predict(input=\"2028總統候選人有誰?\")"],"metadata":{"id":"oIJ2m1mKy9yI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1715327953190,"user_tz":-480,"elapsed":3568,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"89dac130-3715-4e38-fea7-542e9a08b2c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2028年台灣總統候選人包括社恐黨的後藤一里、多利多滋的伊地知虹夏、吃草黨的山田涼和陽光黨的喜多郁代。'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["conversation_with_memory_vs.predict(input=\"我的名字叫做Kevin，很高興認識你\")"],"metadata":{"id":"pT3fpuNZ2KbK","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1715327956085,"user_tz":-480,"elapsed":1469,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"9bd05c8b-30c4-4ab3-9139-8bb6cc218eca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'很高興認識你，Kevin！有什麼可以幫助你的嗎？'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["conversation_with_memory_vs.predict(input=\"你還記得我叫什麼名字嗎?\")"],"metadata":{"id":"24NKeK6t2m4p","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1715327959825,"user_tz":-480,"elapsed":1542,"user":{"displayName":"Kahiroshi","userId":"03154394999392751469"}},"outputId":"35daf610-5a46-45fc-e2e4-3e9568b64ec3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'當然，你的名字是Kevin。有什麼我可以幫助你的嗎？'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"https://github.com/zzxx666413/LLM_RAG20240510/blob/master/langchain_RAG.ipynb","timestamp":1715318855842}]}},"nbformat":4,"nbformat_minor":0}